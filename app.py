import os
import json
import datetime as dt
import streamlit as st

try:
    import google.generativeai as genai
except Exception:
    genai = None


APP_TITLE = "Voice Analyzer | Persona & Voice Spec (Gemini)"
MODEL_NAME = "gemini-3-pro-preview"


# -----------------------------
# Helpers
# -----------------------------
def now_str() -> str:
    return dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def safe_read_text_file(uploaded_file, max_chars=120_000) -> str:
    """Read text from uploaded file with a hard cap to avoid huge prompts."""
    if not uploaded_file:
        return ""
    raw = uploaded_file.read()
    try:
        text = raw.decode("utf-8", errors="ignore")
    except Exception:
        text = str(raw)
    text = text.strip()
    if len(text) > max_chars:
        text = text[:max_chars] + "\n\n[TRUNCATED]"
    return text


def build_prompt(sample_texts: list[str], notes: str, constraints: str, output_language: str) -> str:
    samples_joined = "\n\n".join(sample_texts).strip()
    notes = (notes or "").strip()
    constraints = (constraints or "").strip()

    lang_rule = {
        "ç¹é«”ä¸­æ–‡": "è«‹ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡ºã€‚",
        "English": "Please write in English.",
        "æ—¥æœ¬èª": "æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
    }.get(output_language, "è«‹ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡ºã€‚")

    return f"""
ä½ æ˜¯ä¸€å€‹ã€Œèªæ„Ÿ/é¢¨æ ¼/åƒ¹å€¼è§€ã€åˆ†æå™¨ã€‚ä½ çš„ä»»å‹™ï¼šå¾æ¨£æœ¬æ–‡æœ¬ä¸­æ­¸ç´ä½œè€…çš„ Persona èˆ‡å¯åŸ·è¡Œçš„å¯«ä½œè¦æ ¼ï¼ˆVoice Specï¼‰ï¼Œä¸¦ç”¢å‡ºå¯ç›´æ¥è²¼å…¥å¦ä¸€å€‹å°ˆæ¡ˆå°åŒ…çš„ VOICE CONTEXTã€‚

ã€é‡è¦è¦å‰‡ã€‘
1) ã€Œæ¨£æœ¬æ–‡æœ¬ã€æ˜¯è­‰æ“šå±¤ï¼šä½ åªèƒ½å¾æ¨£æœ¬æ–‡æœ¬æ­¸ç´èªæ„Ÿç‰¹å¾µã€å¥æ³•ã€ç«‹å ´ã€ç¯€å¥ï¼Œä¸å¯æ†‘ç©ºæé€ ä½œè€…èƒŒæ™¯ã€‚
2) ã€Œæˆ‘çš„ç­†è¨˜ã€æ˜¯èªå¢ƒæ ¡æº–å±¤ï¼šå¯ä»¥è£œè¶³ä½œè€…å®šä½/åƒ¹å€¼è§€è„ˆçµ¡ï¼›è‹¥èˆ‡æ¨£æœ¬æ–‡æœ¬è¡çªï¼Œå¿…é ˆæŒ‡å‡ºè¡çªä¸¦çµ¦å‡ºå…©å¥—ç‰ˆæœ¬ï¼ˆV-A: ä»¥æ¨£æœ¬ç‚ºæº–ï¼›V-B: ä»¥ç­†è¨˜ç‚ºæº–ï¼‰ã€‚
3) ç¦æ­¢å¼•ç”¨æ¨£æœ¬æ–‡æœ¬åŸå¥è¶…é 25 å­—ï¼›ä¸å¾—å¤§é‡æŠ„éŒ„ã€‚
4) ä½ çš„è¼¸å‡ºå¿…é ˆå¯åŸ·è¡Œï¼šè¦èƒ½è®“å¦ä¸€å€‹ AI æŒ‰è¦æ ¼ç©©å®šæ¨¡ä»¿å¯«ä½œã€‚
5) {lang_rule}

ã€è¼¸å‡ºæ ¼å¼ï¼ˆåš´æ ¼ï¼‰ã€‘
A) Persona Briefï¼ˆå¯è®€ï¼‰
- ä½œè€…ä¸–ç•Œè§€ä¸€å¥è©±ï¼š
- å°è®€è€…çš„å®šä½ï¼ˆä¸Šå°ä¸‹/ä¸¦è‚©/æŒ‘é‡/å°è©±ï¼‰ï¼š
- æ ¸å¿ƒä¿¡å¿µ/åƒ¹å€¼è§€ï¼ˆ3â€“7æ¢ï¼Œå¥å‹åŒ–ï¼‰ï¼š
- å‹•æ©Ÿé‚Šç•Œï¼ˆä»–ç‚ºä»€éº¼å¯«ã€ä»–ä¸åšä»€éº¼ï¼‰ï¼š
- å…è¨±çš„æ¨¡ç³Šèˆ‡ç•™ç™½ï¼ˆå“ªäº›å¯ä»¥ä¸è¬›æ­»ï¼‰ï¼š
- ç¦èª/ç¦å¥—è·¯ï¼ˆå«ç†ç”±ï¼‰ï¼š

B) Voice Specï¼ˆå¯åŸ·è¡Œï¼‰
- tone_mixï¼ˆ%ï¼‰ï¼šå†·éœ__ / çŠ€åˆ©__ / å¹½é»˜__ / æº«åº¦__
- sentence_rhythmï¼šçŸ­å¥æ¯”ä¾‹__%ï¼›æ¯æ®µ__â€“__è¡Œï¼›è½‰æŠ˜é »ç‡__
- stance_rulesï¼šå¦‚ä½•ä¸‹çµè«–/å¦‚ä½•ç•™ç™½/å¦‚ä½•åå•
- lexical_rulesï¼šå¸¸ç”¨è©/é¿å…è©/ç¦è©
- structure_rulesï¼šå¸¸ç”¨æ¨ç†é †åºï¼ˆä¾‹ï¼šç¾è±¡â†’å°ç…§â†’æ¨è«–â†’é¸é …ï¼‰
- do_notï¼šçµ•å°ç¦æ­¢äº‹é …
- sample_linesï¼ˆ<=5å¥ï¼Œæ¯å¥<=25å­—ï¼Œæ¨¡ä»¿ç”¨ã€ä¸å¯å¼•ç”¨åŸæ–‡ï¼‰ï¼š

C) å¯ç›´æ¥è²¼å…¥å°åŒ…çš„ VOICE CONTEXTï¼ˆè«‹ç”¨ä¸€å€‹ Markdown code block åŒ…èµ·ä¾†ï¼‰
å…§å®¹éœ€é•·å¾—åƒé€™æ¨£ï¼ˆä½ è¦å¡«æ»¿æ¬„ä½ï¼‰ï¼š
=== [VOICE CONTEXT | EDITABLE] ===
[PERSONA LOG]
...
[VOICE SPEC]
...
=== [/VOICE CONTEXT] ===

D) å¿«é€Ÿé©—æ”¶æ¸…å–®ï¼ˆè®“ç¸½ç·¨è¼¯å¿«é€Ÿæª¢æŸ¥æ˜¯å¦åƒä»–ï¼‰
- 3 å€‹ã€Œåƒã€çš„åˆ¤æº–
- 3 å€‹ã€Œä¸åƒã€çš„è­¦æˆ’

ã€é¡å¤–é™åˆ¶/åå¥½ï¼ˆè‹¥æœ‰ï¼Œå¿…é ˆéµå®ˆï¼‰ã€‘
{constraints if constraints else "ï¼ˆç„¡ï¼‰"}

ã€æ¨£æœ¬æ–‡æœ¬ï¼ˆè­‰æ“šå±¤ï¼‰ã€‘
{samples_joined if samples_joined else "ï¼ˆæœªæä¾›æ¨£æœ¬æ–‡æœ¬ï¼Œè«‹å…ˆæŒ‡å‡ºä¸è¶³ï¼Œä¸¦åœ¨å¯æ¨è«–ç¯„åœå…§çµ¦ä¸€ç‰ˆã€ä½ä¿¡å¿ƒã€è¦æ ¼ï¼Œæé†’éœ€è¦æ›´å¤šæ¨£æœ¬ï¼‰"}

ã€æˆ‘çš„ç­†è¨˜ï¼ˆèªå¢ƒæ ¡æº–å±¤ï¼‰ã€‘
{notes if notes else "ï¼ˆæœªæä¾›ï¼‰"}
""".strip()


def call_gemini(api_key: str, prompt: str, temperature: float, max_output_tokens: int) -> str:
    if genai is None:
        raise RuntimeError("google-generativeai æœªå®‰è£æˆ–åŒ¯å…¥å¤±æ•—ã€‚è«‹ç¢ºèª requirements.txt èˆ‡å®‰è£æµç¨‹ã€‚")

    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(MODEL_NAME)

    resp = model.generate_content(
        prompt,
        generation_config={
            "temperature": temperature,
            "max_output_tokens": max_output_tokens,
        },
    )

    # SDK ç‰ˆæœ¬å·®ç•°ï¼šç›¡é‡å…¼å®¹
    text = getattr(resp, "text", None)
    if text:
        return text

    # fallback
    try:
        return resp.candidates[0].content.parts[0].text
    except Exception:
        return str(resp)


# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ§¬", layout="wide")
st.title("ğŸ§¬ Voice Analyzerï¼ˆç¨ç«‹å·¥å…·ï¼‰")
st.caption(f"å›ºå®šæ¨¡å‹ï¼š{MODEL_NAME}ï½œè¼¸å…¥ï¼šæ¨£æœ¬æ–‡æœ¬ + ä½ çš„ç­†è¨˜ï½œè¼¸å‡ºï¼šPersona Brief + Voice Spec + å¯è²¼å…¥å°åŒ…çš„ VOICE CONTEXT")

with st.sidebar:
    st.subheader("ğŸ”‘ Gemini API Key")
    api_key = st.text_input("GEMINI_API_KEY", type="password", value=os.getenv("GEMINI_API_KEY", ""))

    st.divider()
    st.subheader("âš™ï¸ ç”Ÿæˆåƒæ•¸")
    temperature = st.slider("temperature", 0.0, 1.0, 0.4, 0.05)
    max_output_tokens = st.slider("max_output_tokens", 512, 8192, 4096, 256)

    st.divider()
    output_language = st.selectbox("è¼¸å‡ºèªè¨€", ["ç¹é«”ä¸­æ–‡", "English", "æ—¥æœ¬èª"], index=0)

    st.divider()
    st.subheader("ğŸ“¦ è¼¸å‡ºä¿å­˜")
    save_history = st.toggle("ä¿å­˜åˆ°æœ¬æ©Ÿ Session History", value=True)


col1, col2 = st.columns([1, 1], gap="large")

with col1:
    st.subheader("1) æ¨£æœ¬æ–‡æœ¬ï¼ˆè­‰æ“šå±¤ï¼‰")
    st.write("ä¸Šå‚³æˆ–è²¼ä¸Šé€™å€‹äººçš„éå»æ–‡ç« /è²¼æ–‡/è…³æœ¬ã€‚å»ºè­°è‡³å°‘ 1,000â€“3,000 å­—ï¼Œå¤šç¯‡æ›´å¥½ã€‚")

    uploads = st.file_uploader(
        "ä¸Šå‚³ txt / mdï¼ˆå¯å¤šæª”ï¼‰",
        type=["txt", "md"],
        accept_multiple_files=True
    )

    pasted = st.text_area(
        "æˆ–ç›´æ¥è²¼æ¨£æœ¬æ–‡æœ¬ï¼ˆå¯èˆ‡ä¸Šå‚³åŒæ™‚ç”¨ï¼‰",
        height=260,
        placeholder="è²¼ä¸Š 1â€“3 ç¯‡ä»£è¡¨æ€§æ–‡å­—â€¦"
    )

    st.subheader("2) ä½ çš„ç­†è¨˜ï¼ˆèªå¢ƒæ ¡æº–å±¤ï¼‰")
    notes = st.text_area(
        "ä½ å°é€™å€‹äººçš„ç†è§£ï¼šåƒ¹å€¼è§€ã€ç¦å¿Œã€è®€è€…é—œä¿‚ã€å¯«ä½œç›®çš„ã€ä¸å¯ç¢°è§¸çš„é»â€¦",
        height=220,
        placeholder="ä¾‹ï¼šä»–è¨å­é›æ¹¯ï¼›å¯«ä½œè¦æ¨å‹•ç”¢æ¥­æ”¹é©ï¼›å°è®€è€…æ˜¯ä¸¦è‚©è¨è«–è€Œéæ•™å­¸â€¦"
    )

with col2:
    st.subheader("3) é¡å¤–é™åˆ¶ / åå¥½ï¼ˆå¯é¸ï¼‰")
    constraints = st.text_area(
        "ä¾‹å¦‚ï¼šä¸è¦æƒ…ç·’å‹’ç´¢ã€ä¸è¦æ•™æ¢å¼çµè«–ã€è¦å¤šåå•ã€é¿å…ã€ä½ æ‡‰è©²ã€å¥å‹â€¦",
        height=180,
        placeholder="å¯ç•™ç©º"
    )

    st.subheader("4) ä¸€éµç”¢å‡º")
    run = st.button("ğŸš€ é–‹å§‹èªæ„Ÿåˆ†æ", type="primary", use_container_width=True)

    st.info(
        "è¼¸å‡ºæœƒåŒ…å«ï¼šPersona Briefã€Voice Specã€VOICE CONTEXTï¼ˆå¯è²¼å…¥å°åŒ…ï¼‰ã€é©—æ”¶æ¸…å–®ã€‚\n\n"
        "æ³¨æ„ï¼šæ¨£æœ¬æ–‡æœ¬è¶Šå°‘ï¼Œè¦æ ¼æœƒè¶Šã€ä½ä¿¡å¿ƒã€ã€‚"
    )


# Prepare inputs
sample_texts = []
if uploads:
    for f in uploads:
        t = safe_read_text_file(f)
        if t:
            sample_texts.append(f"=== [FILE: {f.name}] ===\n{t}\n=== [/FILE] ===")

if pasted.strip():
    sample_texts.append(f"=== [PASTED] ===\n{pasted.strip()}\n=== [/PASTED] ===")

prompt = build_prompt(sample_texts, notes, constraints, output_language)

# history store
if "history" not in st.session_state:
    st.session_state.history = []

if run:
    if not api_key.strip():
        st.error("ç¼ºå°‘ GEMINI_API_KEYã€‚è«‹åœ¨å´æ¬„è²¼ä¸Šã€‚")
    else:
        with st.spinner("ç”Ÿæˆä¸­â€¦"):
            try:
                output = call_gemini(
                    api_key=api_key.strip(),
                    prompt=prompt,
                    temperature=temperature,
                    max_output_tokens=max_output_tokens
                )
            except Exception as e:
                st.error(f"å‘¼å« Gemini å¤±æ•—ï¼š{e}")
                output = ""

        if output:
            st.subheader("âœ… ç”Ÿæˆçµæœ")
            st.write(output)

            if save_history:
                st.session_state.history.insert(
                    0,
                    {
                        "ts": now_str(),
                        "model": MODEL_NAME,
                        "temperature": temperature,
                        "max_output_tokens": max_output_tokens,
                        "output_language": output_language,
                        "constraints": constraints,
                        "has_samples": bool(sample_texts),
                        "output": output,
                    }
                )

            st.divider()
            st.subheader("â¬‡ï¸ åŒ¯å‡º")
            export_payload = {
                "meta": {
                    "ts": now_str(),
                    "model": MODEL_NAME,
                    "temperature": temperature,
                    "max_output_tokens": max_output_tokens,
                    "output_language": output_language,
                },
                "input": {
                    "constraints": constraints,
                    "notes": notes,
                    "samples_count": len(sample_texts),
                },
                "output": output,
            }
            st.download_button(
                "ä¸‹è¼‰ JSONï¼ˆå«è¼¸å…¥/è¼¸å‡ºï¼‰",
                data=json.dumps(export_payload, ensure_ascii=False, indent=2),
                file_name=f"voice_analysis_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
            st.download_button(
                "ä¸‹è¼‰ TXTï¼ˆåªå«è¼¸å‡ºï¼‰",
                data=output,
                file_name=f"voice_analysis_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain; charset=utf-8",
                use_container_width=True
            )

st.divider()
st.subheader("ğŸ“š Session Historyï¼ˆæœ¬æ¬¡ç€è¦½å™¨æœŸé–“ï¼‰")
if st.session_state.history:
    for i, item in enumerate(st.session_state.history[:10], start=1):
        with st.expander(f"{i}. {item['ts']} | {item['model']} | temp={item['temperature']}"):
            st.write(item["output"])
else:
    st.caption("å°šç„¡ç´€éŒ„ã€‚")
